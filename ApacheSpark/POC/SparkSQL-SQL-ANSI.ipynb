{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL\n",
    "\n",
    "Pacotes adicionais do Spark: https://spark-packages.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando o contexto em que se encontra a conexão: \n",
      "\n",
      "<SparkContext master=local[*] appName=PySparkShell>\n",
      "\n",
      " Versão do SPARK em execução: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "\n",
    "print('Verificando o contexto em que se encontra a conexão:', '\\n')\n",
    "print(sc) #sc = spark context\n",
    "print('\\n', 'Versão do SPARK em execução:', sc.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkContext -> conexão Python-Spark (pelo Jupyter é criado automáticamente com a chamado do PySpark)\n",
    "\n",
    "Em aplicações profissionais (deploy de solução em PRODUÇÃO), é necessário CONSTRUIR o CONTEXTO (explicitamente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSession ->>> trabalhar com DataFrames no SparkSQL, necessário CONSTRUIR uma SESSÃO (explicitamente)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spSession = SparkSession.builder.master(\"local\").appName(\"POC-SparkSQL\")\\\n",
    "          .config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLContext ->>> trabalhar com LINGUAGEM SQL no SparkSQL, necessário CONSTRUIR o CONTEXTO (explicitamente)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlSession = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando arquivo CSV e criando a RDD..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo do objeto criado <carRDD>: <class 'pyspark.rdd.RDD'>\n",
      "Quantidade de elementos do objeto RDD criado <carRDD> 198 \n",
      "\n",
      "Exibindo as 5 primeiras linhas do RDD criado <carRDD>... \n",
      " ['MAKE,FUELTYPE,ASPIRE,DOORS,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE', 'subaru,gas,std,two,hatchback,fwd,four,69,4900,31,36,5118', 'chevrolet,gas,std,two,hatchback,fwd,three,48,5100,47,53,5151', 'mazda,gas,std,two,hatchback,fwd,four,68,5000,30,31,5195', 'toyota,gas,std,two,hatchback,fwd,four,62,4800,35,39,5348'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#file =\"/home/daniellj/Projetos/Github/DistributedComputing/ApacheSpark/datasets/cars.csv\"\n",
    "file = \"C:\\\\Users\\\\whitecube.daniel\\\\Projetos_Daniel\\\\DistributedComputing\\\\Datasets\\\\cars.csv\"\n",
    "carRDD = sc.textFile(file)\n",
    "\n",
    "print('Tipo do objeto criado <carRDD>:', type(carRDD))\n",
    "print('Quantidade de elementos do objeto RDD criado <carRDD>', carRDD.count(), '\\n')\n",
    "print('Exibindo as 5 primeiras linhas do RDD criado <carRDD>...', '\\n',carRDD.take(5),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD é um repositório de dados genéricos. É possível colocar qualquer coisa dentro de uma RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de elementos onde não há linhas com a expressão \"PRICE\": 197 \n",
      "\n",
      "Ajustando os dados com quebras a partir das vírgulas...exibindo as primeiras linhas após o ajustes...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['subaru',\n",
       "  'gas',\n",
       "  'std',\n",
       "  'two',\n",
       "  'hatchback',\n",
       "  'fwd',\n",
       "  'four',\n",
       "  '69',\n",
       "  '4900',\n",
       "  '31',\n",
       "  '36',\n",
       "  '5118'],\n",
       " ['chevrolet',\n",
       "  'gas',\n",
       "  'std',\n",
       "  'two',\n",
       "  'hatchback',\n",
       "  'fwd',\n",
       "  'three',\n",
       "  '48',\n",
       "  '5100',\n",
       "  '47',\n",
       "  '53',\n",
       "  '5151']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowRDD2 = carRDD.filter(lambda x : 'PRICE' not in x)\n",
    "print('Quantidade de elementos onde não há linhas com a expressão \"PRICE\":', rowRDD2.count(), '\\n')\n",
    "\n",
    "print('Ajustando os dados com quebras a partir das vírgulas...exibindo as primeiras linhas após o ajustes...')\n",
    "rowRDD3 = rowRDD2.map(lambda x: x.split(','))\n",
    "rowRDD3.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Row can be used to create a row object by using named arguments,\n",
    "the fields will be sorted by names. It is not allowed to omit\n",
    "a named argument to represent the value is None or missing. This should be\n",
    "explicitly set to None in this case.\n",
    "\n",
    ">>> row = Row(name=\"Alice\", age=11)\n",
    ">>> row\n",
    "Row(age=11, name='Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Row implementada à seguir: divide o RDD e transforma cada linha em um objeto INDEPENDENTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowRDD4 = rowRDD3.map(lambda x: Row(make = x[0], body = x[4], hp = x[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exibindo as 20 primeiras linhas independentes criadas <rowRDD4>...\n",
      "Observe que a ordenação dos parâmetros se dá por ordem alfabética.\n",
      "A ordenação dos registros segue o estado original... \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(body='hatchback', hp='69', make='subaru'),\n",
       " Row(body='hatchback', hp='48', make='chevrolet'),\n",
       " Row(body='hatchback', hp='68', make='mazda'),\n",
       " Row(body='hatchback', hp='62', make='toyota'),\n",
       " Row(body='hatchback', hp='68', make='mitsubishi'),\n",
       " Row(body='hatchback', hp='60', make='honda'),\n",
       " Row(body='sedan', hp='69', make='nissan'),\n",
       " Row(body='hatchback', hp='68', make='dodge'),\n",
       " Row(body='hatchback', hp='68', make='plymouth'),\n",
       " Row(body='hatchback', hp='68', make='mazda'),\n",
       " Row(body='hatchback', hp='68', make='mitsubishi'),\n",
       " Row(body='hatchback', hp='68', make='dodge'),\n",
       " Row(body='hatchback', hp='68', make='plymouth'),\n",
       " Row(body='hatchback', hp='70', make='chevrolet'),\n",
       " Row(body='hatchback', hp='62', make='toyota'),\n",
       " Row(body='hatchback', hp='68', make='dodge'),\n",
       " Row(body='hatchback', hp='58', make='honda'),\n",
       " Row(body='hatchback', hp='62', make='toyota'),\n",
       " Row(body='hatchback', hp='76', make='honda'),\n",
       " Row(body='sedan', hp='70', make='chevrolet')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Exibindo as 20 primeiras linhas independentes criadas <rowRDD4>...')\n",
    "print('Observe que a ordenação dos parâmetros se dá por ordem alfabética.')\n",
    "print('A ordenação dos registros segue o estado original...', '\\n')\n",
    "rowRDD4.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ### Criando um dataframe, a partir de uma RDD, usando a SPARK CONTEXT criada anteriormente...\n",
    " \n",
    " Internamente, RDD = DataFrame.\n",
    " Vantagem dos DataFrames: maior facilidade de manipular dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo do objeto criado <rowRDD5>: <class 'pyspark.sql.dataframe.DataFrame'> \n",
      "\n",
      "Imprimindo as 15 primeiras linhas do DataFrame criado... \n",
      "\n",
      "+---------+---+----------+\n",
      "|     body| hp|      make|\n",
      "+---------+---+----------+\n",
      "|hatchback| 69|    subaru|\n",
      "|hatchback| 48| chevrolet|\n",
      "|hatchback| 68|     mazda|\n",
      "|hatchback| 62|    toyota|\n",
      "|hatchback| 68|mitsubishi|\n",
      "|hatchback| 60|     honda|\n",
      "|    sedan| 69|    nissan|\n",
      "|hatchback| 68|     dodge|\n",
      "|hatchback| 68|  plymouth|\n",
      "|hatchback| 68|     mazda|\n",
      "|hatchback| 68|mitsubishi|\n",
      "|hatchback| 68|     dodge|\n",
      "|hatchback| 68|  plymouth|\n",
      "|hatchback| 70| chevrolet|\n",
      "|hatchback| 62|    toyota|\n",
      "+---------+---+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rowRDD5 = spSession.createDataFrame(rowRDD4)\n",
    "print('Tipo do objeto criado <rowRDD5>:', type(rowRDD5), '\\n')\n",
    "\n",
    "print('Imprimindo as 15 primeiras linhas do DataFrame criado...', '\\n')\n",
    "rowRDD5.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SparkSQL command - Fazendo manipulações de dados do DataFrame criado em SparkSQL..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta com select... \n",
      "\n",
      "+---------+---+----------+\n",
      "|     body| hp|      make|\n",
      "+---------+---+----------+\n",
      "|hatchback| 69|    subaru|\n",
      "|hatchback| 48| chevrolet|\n",
      "|hatchback| 68|     mazda|\n",
      "|hatchback| 62|    toyota|\n",
      "|hatchback| 68|mitsubishi|\n",
      "|hatchback| 60|     honda|\n",
      "|    sedan| 69|    nissan|\n",
      "|hatchback| 68|     dodge|\n",
      "|hatchback| 68|  plymouth|\n",
      "|hatchback| 68|     mazda|\n",
      "+---------+---+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Consulta com select...', '\\n')\n",
    "rowRDD5.select('*').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSQL command - Ordenando os dados do DataFrame por uma das colunas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-----------+\n",
      "|       body| hp|       make|\n",
      "+-----------+---+-----------+\n",
      "|  hatchback|154|alfa-romero|\n",
      "|convertible|111|alfa-romero|\n",
      "|convertible|111|alfa-romero|\n",
      "|      sedan|110|       audi|\n",
      "|      sedan|115|       audi|\n",
      "|      sedan|110|       audi|\n",
      "|      wagon|110|       audi|\n",
      "|      sedan|140|       audi|\n",
      "|      sedan|102|       audi|\n",
      "|      sedan|101|        bmw|\n",
      "|      sedan|101|        bmw|\n",
      "|      sedan|121|        bmw|\n",
      "|      sedan|121|        bmw|\n",
      "|      sedan|182|        bmw|\n",
      "|      sedan|182|        bmw|\n",
      "|      sedan|121|        bmw|\n",
      "|      sedan|182|        bmw|\n",
      "|      sedan| 70|  chevrolet|\n",
      "|  hatchback| 70|  chevrolet|\n",
      "|  hatchback| 48|  chevrolet|\n",
      "+-----------+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rowRDD5.orderBy('make').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quando queremos utilizar a LINGUAGEM SQL, convertemos o conteúdo de origem (no cenário atual o DataFrame) para uma TABELA TEMPORÁRIA\n",
    "### Convertendo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rowRDD5.createOrReplaceTempView('rowTB1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir do momento que temos a tabela temporária criada, podemos disparar comandos SQL ANSI contra este objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparando uma consulta contra a tabela temporária <rowTB1>... \n",
      "\n",
      "Exibindo todos os registros que sejam da marca \"honda\"... \n",
      "\n",
      "+---------+---+-----+\n",
      "|     body| hp| make|\n",
      "+---------+---+-----+\n",
      "|hatchback| 60|honda|\n",
      "|hatchback| 58|honda|\n",
      "|hatchback| 76|honda|\n",
      "|hatchback| 76|honda|\n",
      "|hatchback| 76|honda|\n",
      "|    sedan| 76|honda|\n",
      "|    wagon| 76|honda|\n",
      "|hatchback| 86|honda|\n",
      "|    sedan| 86|honda|\n",
      "|hatchback| 86|honda|\n",
      "|    sedan| 86|honda|\n",
      "|    sedan|100|honda|\n",
      "|    sedan|101|honda|\n",
      "+---------+---+-----+\n",
      "\n",
      "\n",
      " Exibindo a média de HP dos carros agrupados por marca, onde marcas avaliadas são \"honda\" e \"bmw\"... \n",
      "\n",
      "+-----+------+\n",
      "| make|    hp|\n",
      "+-----+------+\n",
      "|  bmw|138.88|\n",
      "|honda| 80.23|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Disparando uma consulta contra a tabela temporária <rowTB1>...', '\\n')\n",
    "\n",
    "print('Exibindo todos os registros que sejam da marca \"honda\"...', '\\n')\n",
    "spSession.sql('select * from rowTB1 where make = \"honda\"').show()\n",
    "\n",
    "print('\\n', 'Exibindo a média de HP dos carros agrupados por marca, onde marcas avaliadas são \"honda\" e \"bmw\"...', '\\n')\n",
    "spSession.sql('select make, cast(avg(hp) as decimal(10,2)) as hp from rowTB1 where make IN (\"honda\",\"bmw\") group by make').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando arquivo CSV e criando o DataFrame (diretamente)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo do objeto criado <carsDataFrame>: <class 'pyspark.sql.dataframe.DataFrame'> \n",
      "\n",
      "Imprimindo as 10 primeiras linhas do DataFrame criado... \n",
      "\n",
      "+----------+--------+------+-----+---------+-----+---------+---+----+--------+-------+-----+\n",
      "|      MAKE|FUELTYPE|ASPIRE|DOORS|     BODY|DRIVE|CYLINDERS| HP| RPM|MPG-CITY|MPG-HWY|PRICE|\n",
      "+----------+--------+------+-----+---------+-----+---------+---+----+--------+-------+-----+\n",
      "|    subaru|     gas|   std|  two|hatchback|  fwd|     four| 69|4900|      31|     36| 5118|\n",
      "| chevrolet|     gas|   std|  two|hatchback|  fwd|    three| 48|5100|      47|     53| 5151|\n",
      "|     mazda|     gas|   std|  two|hatchback|  fwd|     four| 68|5000|      30|     31| 5195|\n",
      "|    toyota|     gas|   std|  two|hatchback|  fwd|     four| 62|4800|      35|     39| 5348|\n",
      "|mitsubishi|     gas|   std|  two|hatchback|  fwd|     four| 68|5500|      37|     41| 5389|\n",
      "|     honda|     gas|   std|  two|hatchback|  fwd|     four| 60|5500|      38|     42| 5399|\n",
      "|    nissan|     gas|   std|  two|    sedan|  fwd|     four| 69|5200|      31|     37| 5499|\n",
      "|     dodge|     gas|   std|  two|hatchback|  fwd|     four| 68|5500|      37|     41| 5572|\n",
      "|  plymouth|     gas|   std|  two|hatchback|  fwd|     four| 68|5500|      37|     41| 5572|\n",
      "|     mazda|     gas|   std|  two|hatchback|  fwd|     four| 68|5000|      31|     38| 6095|\n",
      "+----------+--------+------+-----+---------+-----+---------+---+----+--------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#file =\"/home/daniellj/Projetos/Github/DistributedComputing/ApacheSpark/datasets/cars.csv\"\n",
    "file = \"C:\\\\Users\\\\whitecube.daniel\\\\Projetos_Daniel\\\\DistributedComputing\\\\Datasets\\\\cars.csv\"\n",
    "\n",
    "rowRDD5 = spSession.read.csv(file, header=True) # header -> informando que o arquivo tem cabeçalho\n",
    "\n",
    "print('Tipo do objeto criado <carsDataFrame>:', type(rowRDD5), '\\n')\n",
    "print('Imprimindo as 10 primeiras linhas do DataFrame criado...', '\\n')\n",
    "rowRDD5.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com o DataFrame criado, agora novamente iremos criar a TABELA TEMPORÁRIA para poder usar a manipulação com linguagem SQL ANSI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowRDD5.createOrReplaceTempView(\"rowTB2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com a tabela temporária criada, podemos disparar comandos SQL-ANSI sobre o objeto criado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|  make| RPM|price|\n",
      "+------+----+-----+\n",
      "| dodge|5000|12964|\n",
      "| dodge|5500| 5572|\n",
      "| dodge|5500| 6229|\n",
      "| dodge|5500| 6377|\n",
      "| dodge|5500| 6692|\n",
      "| dodge|5500| 7609|\n",
      "| dodge|5500| 7957|\n",
      "| dodge|5000| 8921|\n",
      "|subaru|5200|10198|\n",
      "|subaru|4800|11259|\n",
      "|subaru|4800|11694|\n",
      "|subaru|4900| 5118|\n",
      "|subaru|4400| 7053|\n",
      "|subaru|4800| 7126|\n",
      "|subaru|4800| 7463|\n",
      "|subaru|4400| 7603|\n",
      "|subaru|4400| 7775|\n",
      "|subaru|4800| 8013|\n",
      "|subaru|4800| 9233|\n",
      "|subaru|5200| 9960|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rowTB3 = spSession.sql('select make, RPM, price from rowTB2 where make IN (\"subaru\", \"dodge\") order by make ASC, price ASC')\n",
    "rowTB3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
